{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 2: Genomic Variant Analysis\n",
        "\n",
        "**From raw variants to population genetics and GWAS**\n",
        "\n",
        "Prerequisites: Notebook 1 (sequence objects, alignment, file parsing)\n",
        "\n",
        "This notebook builds:\n",
        "1. VCF file parsing and variant representation\n",
        "2. Variant statistics (allele frequencies, Hardy-Weinberg equilibrium)\n",
        "3. Population structure analysis (PCA on genotypes)\n",
        "4. Linkage disequilibrium\n",
        "5. Genome-wide association study (GWAS) simulation\n",
        "6. Manhattan and QQ plots\n",
        "\n",
        "Estimated runtime: ~5 min on laptop\n",
        "\n",
        "**Key learning outcomes:**\n",
        "1. Understand genetic variation as the raw material of evolution\n",
        "2. Parse and analyze VCF files programmatically\n",
        "3. Compute population genetics statistics (allele frequency, HWE, Fst)\n",
        "4. Perform PCA to reveal population structure — see [[Fitness Landscapes]]\n",
        "5. Simulate and visualize a GWAS — see [[Variant-Phenotype Mapping]]"
      ],
      "id": "a1b2c3d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 0: Setup"
      ],
      "id": "b2c3d4e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.decomposition import PCA\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"Ready — using numpy, scipy, sklearn, matplotlib\")"
      ],
      "id": "c3d4e5f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Note:** We use numpy/scipy for core computation rather than requiring scikit-allel, making this notebook zero-dependency beyond standard scientific Python. In practice, scikit-allel and cyvcf2 handle real VCF files."
      ],
      "id": "d4e5f6a7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Variant Representation\n",
        "\n",
        "A genetic variant is a position where individuals differ from the reference genome. The most common type is a **Single Nucleotide Polymorphism (SNP)** — a single base change. See [[Variant Effect Prediction]].\n",
        "\n",
        "VCF (Variant Call Format) is the standard file format:\n",
        "```\n",
        "#CHROM  POS  ID       REF  ALT  QUAL  FILTER  INFO        FORMAT  Sample1  Sample2\n",
        "chr1    100  rs123    A    G    99    PASS    AF=0.3      GT      0/1      1/1\n",
        "```\n",
        "\n",
        "Genotype encoding:\n",
        "- `0/0` = homozygous reference (0)\n",
        "- `0/1` = heterozygous (1)\n",
        "- `1/1` = homozygous alternate (2)"
      ],
      "id": "e5f6a7b8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate genotype data for 200 individuals at 1000 SNPs\n",
        "np.random.seed(42)\n",
        "n_individuals = 200\n",
        "n_snps = 1000\n",
        "\n",
        "# Minor allele frequencies drawn from a realistic distribution\n",
        "# (most variants are rare — exponential-like distribution)\n",
        "mafs = np.random.beta(0.5, 5, n_snps)  # Skewed toward low frequency\n",
        "mafs = np.clip(mafs, 0.01, 0.49)\n",
        "\n",
        "# Generate genotypes: 0 (ref/ref), 1 (ref/alt), 2 (alt/alt)\n",
        "# Under Hardy-Weinberg: P(0)=(1-p)^2, P(1)=2p(1-p), P(2)=p^2\n",
        "genotypes = np.zeros((n_individuals, n_snps), dtype=int)\n",
        "for j in range(n_snps):\n",
        "    p = mafs[j]\n",
        "    probs = [(1-p)**2, 2*p*(1-p), p**2]\n",
        "    genotypes[:, j] = np.random.choice([0, 1, 2], size=n_individuals, p=probs)\n",
        "\n",
        "print(f\"Genotype matrix: {genotypes.shape} (individuals x SNPs)\")\n",
        "print(f\"Genotype encoding: 0=ref/ref, 1=ref/alt, 2=alt/alt\")\n",
        "print(f\"Example (first 5 individuals, first 10 SNPs):\")\n",
        "print(genotypes[:5, :10])"
      ],
      "id": "f6a7b8c9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute observed allele frequencies\n",
        "observed_af = genotypes.sum(axis=0) / (2 * n_individuals)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "ax1.hist(observed_af, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "ax1.set_xlabel('Minor Allele Frequency')\n",
        "ax1.set_ylabel('Number of SNPs')\n",
        "ax1.set_title('Site Frequency Spectrum\\n(Most variants are rare)')\n",
        "ax1.axvline(0.05, color='red', linestyle='--', label='MAF = 5% threshold')\n",
        "ax1.legend()\n",
        "\n",
        "# Compare input vs observed MAFs\n",
        "ax2.scatter(mafs, observed_af, alpha=0.3, s=10)\n",
        "ax2.plot([0, 0.5], [0, 0.5], 'r--', label='Perfect recovery')\n",
        "ax2.set_xlabel('True MAF')\n",
        "ax2.set_ylabel('Observed MAF')\n",
        "ax2.set_title('True vs Observed Allele Frequencies')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f\"Rare variants (MAF < 5%): {(observed_af < 0.05).sum()} / {n_snps}\")\n",
        "print(f\"Common variants (MAF >= 5%): {(observed_af >= 0.05).sum()} / {n_snps}\")"
      ],
      "id": "a7b8c9d0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Per-SNP genotype counts\n",
        "het_rates = (genotypes == 1).sum(axis=0) / n_individuals\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(observed_af, het_rates, alpha=0.3, s=10, color='steelblue')\n",
        "\n",
        "# Theoretical heterozygosity under HWE: H = 2p(1-p)\n",
        "p_range = np.linspace(0, 0.5, 100)\n",
        "plt.plot(p_range, 2 * p_range * (1 - p_range), 'r-', linewidth=2, label='HWE expectation: 2p(1-p)')\n",
        "plt.xlabel('Allele Frequency')\n",
        "plt.ylabel('Heterozygosity')\n",
        "plt.title('Heterozygosity vs Allele Frequency\\n(Hardy-Weinberg Equilibrium check)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "id": "b8c9d0e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Hardy-Weinberg Equilibrium\n",
        "\n",
        "Hardy-Weinberg Equilibrium (HWE) states that in the absence of evolution (no selection, drift, mutation, migration, or non-random mating), genotype frequencies are:\n",
        "\n",
        "$$P(AA) = p^2, \\quad P(Aa) = 2pq, \\quad P(aa) = q^2$$\n",
        "\n",
        "where $p + q = 1$. Deviations from HWE signal biological processes at work. See [[Conservation Laws in Living Systems]]."
      ],
      "id": "c9d0e1f2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test each SNP for HWE deviation using chi-squared test\n",
        "hwe_pvalues = []\n",
        "for j in range(n_snps):\n",
        "    obs = np.array([\n",
        "        (genotypes[:, j] == 0).sum(),  # ref/ref\n",
        "        (genotypes[:, j] == 1).sum(),  # ref/alt\n",
        "        (genotypes[:, j] == 2).sum(),  # alt/alt\n",
        "    ])\n",
        "    p = observed_af[j]\n",
        "    q = 1 - p\n",
        "    exp = np.array([q**2, 2*p*q, p**2]) * n_individuals\n",
        "    \n",
        "    # Avoid division by zero\n",
        "    if all(exp > 0):\n",
        "        chi2 = ((obs - exp)**2 / exp).sum()\n",
        "        pval = 1 - stats.chi2.cdf(chi2, df=1)  # 1 df for HWE\n",
        "    else:\n",
        "        pval = 1.0\n",
        "    hwe_pvalues.append(pval)\n",
        "\n",
        "hwe_pvalues = np.array(hwe_pvalues)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(hwe_pvalues, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "plt.axhline(y=n_snps/50, color='red', linestyle='--', label='Uniform expectation')\n",
        "plt.xlabel('HWE p-value')\n",
        "plt.ylabel('Number of SNPs')\n",
        "plt.title('Hardy-Weinberg Equilibrium Test Results\\n(Uniform under null = data consistent with HWE)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "n_sig = (hwe_pvalues < 0.05).sum()\n",
        "print(f\"SNPs deviating from HWE (p < 0.05): {n_sig} / {n_snps}\")\n",
        "print(f\"Expected by chance at alpha=0.05: ~{int(0.05 * n_snps)}\")"
      ],
      "id": "d0e1f2a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# QQ plot: compare observed p-values to uniform distribution\n",
        "observed_log = -np.log10(np.sort(hwe_pvalues))\n",
        "expected_log = -np.log10(np.linspace(1/n_snps, 1, n_snps))\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.scatter(expected_log, observed_log, alpha=0.3, s=10, color='steelblue')\n",
        "max_val = max(expected_log.max(), observed_log.max()) + 0.5\n",
        "plt.plot([0, max_val], [0, max_val], 'r--', label='y = x (null)')\n",
        "plt.xlabel('Expected -log10(p)')\n",
        "plt.ylabel('Observed -log10(p)')\n",
        "plt.title('QQ Plot: HWE Test\\n(Points on diagonal = no inflation)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "id": "e1f2a3b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: Population Structure (PCA)\n",
        "\n",
        "Population structure reveals genetic ancestry. PCA on genotype matrices separates populations. This is critical for GWAS — population structure is a confounding factor that causes false positives. See [[Context Conditionality]] — genotype effects depend on population context."
      ],
      "id": "f2a3b4c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create 3 populations with slightly different allele frequencies\n",
        "np.random.seed(42)\n",
        "n_per_pop = 100\n",
        "n_snps_pop = 500\n",
        "\n",
        "# Base allele frequencies\n",
        "base_mafs = np.random.beta(1, 5, n_snps_pop)\n",
        "base_mafs = np.clip(base_mafs, 0.05, 0.45)\n",
        "\n",
        "# Population-specific frequencies (drift from base)\n",
        "drift = 0.05\n",
        "pop_mafs = np.zeros((3, n_snps_pop))\n",
        "for k in range(3):\n",
        "    pop_mafs[k] = np.clip(base_mafs + np.random.normal(0, drift, n_snps_pop), 0.01, 0.99)\n",
        "\n",
        "# Generate genotypes for each population\n",
        "pop_genotypes = []\n",
        "pop_labels = []\n",
        "for k in range(3):\n",
        "    geno = np.zeros((n_per_pop, n_snps_pop), dtype=int)\n",
        "    for j in range(n_snps_pop):\n",
        "        p = pop_mafs[k, j]\n",
        "        probs = [(1-p)**2, 2*p*(1-p), p**2]\n",
        "        geno[:, j] = np.random.choice([0, 1, 2], size=n_per_pop, p=probs)\n",
        "    pop_genotypes.append(geno)\n",
        "    pop_labels.extend([f'Pop {k+1}'] * n_per_pop)\n",
        "\n",
        "genotypes_all = np.vstack(pop_genotypes)\n",
        "print(f\"Combined genotype matrix: {genotypes_all.shape}\")\n",
        "print(f\"Populations: {Counter(pop_labels)}\")"
      ],
      "id": "a3b4c5d6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize genotypes (mean-center, unit variance per SNP)\n",
        "geno_mean = genotypes_all.mean(axis=0)\n",
        "geno_std = genotypes_all.std(axis=0)\n",
        "geno_std[geno_std == 0] = 1  # Avoid division by zero for monomorphic sites\n",
        "geno_standardized = (genotypes_all - geno_mean) / geno_std\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=10)\n",
        "pcs = pca.fit_transform(geno_standardized)\n",
        "\n",
        "# Plot PC1 vs PC2\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "colors_pop = {'Pop 1': '#e74c3c', 'Pop 2': '#3498db', 'Pop 3': '#2ecc71'}\n",
        "for label in ['Pop 1', 'Pop 2', 'Pop 3']:\n",
        "    mask = np.array(pop_labels) == label\n",
        "    ax1.scatter(pcs[mask, 0], pcs[mask, 1], alpha=0.6, s=20, label=label, color=colors_pop[label])\n",
        "\n",
        "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "ax1.set_title('Population Structure via Genotype PCA')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Scree plot\n",
        "ax2.bar(range(1, 11), pca.explained_variance_ratio_[:10] * 100, color='steelblue')\n",
        "ax2.set_xlabel('Principal Component')\n",
        "ax2.set_ylabel('Variance Explained (%)')\n",
        "ax2.set_title('PCA Scree Plot')\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "b4c5d6e7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wright's Fst: measures genetic differentiation between populations\n",
        "def compute_fst(geno_pop1, geno_pop2):\n",
        "    \"\"\"Compute per-SNP Fst (Weir-Cockerham estimator, simplified).\"\"\"\n",
        "    p1 = geno_pop1.sum(axis=0) / (2 * geno_pop1.shape[0])\n",
        "    p2 = geno_pop2.sum(axis=0) / (2 * geno_pop2.shape[0])\n",
        "    p_mean = (p1 + p2) / 2\n",
        "    \n",
        "    h_t = 2 * p_mean * (1 - p_mean)  # Total heterozygosity\n",
        "    h_s = (2 * p1 * (1-p1) + 2 * p2 * (1-p2)) / 2  # Subpop heterozygosity\n",
        "    \n",
        "    # Fst = (Ht - Hs) / Ht\n",
        "    valid = h_t > 0\n",
        "    fst = np.zeros(len(p1))\n",
        "    fst[valid] = (h_t[valid] - h_s[valid]) / h_t[valid]\n",
        "    return fst\n",
        "\n",
        "fst_12 = compute_fst(pop_genotypes[0], pop_genotypes[1])\n",
        "fst_13 = compute_fst(pop_genotypes[0], pop_genotypes[2])\n",
        "fst_23 = compute_fst(pop_genotypes[1], pop_genotypes[2])\n",
        "\n",
        "print(f\"Mean Fst (Pop1 vs Pop2): {np.mean(fst_12):.4f}\")\n",
        "print(f\"Mean Fst (Pop1 vs Pop3): {np.mean(fst_13):.4f}\")\n",
        "print(f\"Mean Fst (Pop2 vs Pop3): {np.mean(fst_23):.4f}\")\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(fst_12, bins=50, alpha=0.5, label='Pop1 vs Pop2', color='#e74c3c')\n",
        "plt.hist(fst_23, bins=50, alpha=0.5, label='Pop2 vs Pop3', color='#3498db')\n",
        "plt.xlabel('Fst')\n",
        "plt.ylabel('Number of SNPs')\n",
        "plt.title(\"Wright's Fst Distribution\\n(Higher = more differentiated)\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "id": "c5d6e7f8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Linkage Disequilibrium\n",
        "\n",
        "Linkage disequilibrium (LD) is the non-random association of alleles at different loci. Nearby SNPs tend to be inherited together. LD decays with distance (recombination breaks up haplotypes). LD is critical for GWAS — a significant SNP may not be causal but merely in LD with the causal variant."
      ],
      "id": "d6e7f8a9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute LD (r squared) between pairs of nearby SNPs\n",
        "# Using the first population for clarity\n",
        "geno_pop1 = pop_genotypes[0]\n",
        "n_show = 50  # First 50 SNPs\n",
        "\n",
        "# Compute r squared matrix\n",
        "r2_matrix = np.corrcoef(geno_pop1[:, :n_show].T) ** 2\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(r2_matrix, cmap='YlOrRd', interpolation='nearest')\n",
        "plt.colorbar(label='r squared')\n",
        "plt.xlabel('SNP index')\n",
        "plt.ylabel('SNP index')\n",
        "plt.title('Linkage Disequilibrium (r squared) Matrix\\n(First 50 SNPs)')\n",
        "plt.show()"
      ],
      "id": "e7f8a9b0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate LD decay (in real data, nearby SNPs have higher LD)\n",
        "# Add synthetic correlation structure\n",
        "np.random.seed(42)\n",
        "n_snps_ld = 200\n",
        "geno_corr = np.random.randn(n_per_pop, n_snps_ld)\n",
        "\n",
        "# Add correlation between nearby SNPs (exponential decay)\n",
        "for j in range(1, n_snps_ld):\n",
        "    decay = np.exp(-j * 0.05)  # Decay rate\n",
        "    for k in range(max(0, j-20), j):\n",
        "        rho = np.exp(-(j-k) * 0.1)\n",
        "        geno_corr[:, j] += rho * geno_corr[:, k]\n",
        "\n",
        "# Discretize to genotypes\n",
        "geno_corr = np.digitize(geno_corr, bins=[-0.5, 0.5])  # 0, 1, 2\n",
        "\n",
        "# Compute LD vs distance\n",
        "distances = []\n",
        "r2_values = []\n",
        "for i in range(0, n_snps_ld, 2):\n",
        "    for j in range(i+1, min(i+50, n_snps_ld)):\n",
        "        r = np.corrcoef(geno_corr[:, i], geno_corr[:, j])[0, 1]\n",
        "        distances.append(j - i)\n",
        "        r2_values.append(r**2)\n",
        "\n",
        "# Bin and average\n",
        "dist_arr = np.array(distances)\n",
        "r2_arr = np.array(r2_values)\n",
        "bins = np.arange(1, 51)\n",
        "mean_r2 = [r2_arr[dist_arr == d].mean() for d in bins if (dist_arr == d).sum() > 0]\n",
        "valid_bins = [d for d in bins if (dist_arr == d).sum() > 0]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(distances, r2_values, alpha=0.05, s=5, color='gray')\n",
        "plt.plot(valid_bins, mean_r2, 'r-', linewidth=2, label='Mean r squared')\n",
        "plt.xlabel('Distance (SNPs apart)')\n",
        "plt.ylabel('r squared')\n",
        "plt.title('LD Decay with Distance\\n(Recombination breaks up haplotypes)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ],
      "id": "f8a9b0c1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: GWAS Simulation\n",
        "\n",
        "A Genome-Wide Association Study (GWAS) tests each SNP for association with a phenotype (disease, trait). The key challenge: testing thousands of SNPs requires correction for multiple testing. See [[Variant-Phenotype Mapping]] and [[Genotype-to-Phenotype Hub]].\n",
        "\n",
        "The GWAS model for quantitative traits:\n",
        "\n",
        "$$y = X\\beta + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2)$$\n",
        "\n",
        "For each SNP $j$, we test $H_0: \\beta_j = 0$ vs $H_1: \\beta_j \\neq 0$."
      ],
      "id": "a9b0c1d2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate a quantitative trait influenced by 5 causal SNPs\n",
        "np.random.seed(42)\n",
        "n_gwas = 300\n",
        "n_snps_gwas = 5000\n",
        "\n",
        "# Genotypes (use first population to avoid structure confounding)\n",
        "mafs_gwas = np.random.beta(1, 5, n_snps_gwas)\n",
        "mafs_gwas = np.clip(mafs_gwas, 0.05, 0.45)\n",
        "\n",
        "geno_gwas = np.zeros((n_gwas, n_snps_gwas), dtype=int)\n",
        "for j in range(n_snps_gwas):\n",
        "    p = mafs_gwas[j]\n",
        "    probs = [(1-p)**2, 2*p*(1-p), p**2]\n",
        "    geno_gwas[:, j] = np.random.choice([0, 1, 2], size=n_gwas, p=probs)\n",
        "\n",
        "# Causal SNPs (randomly chosen)\n",
        "causal_indices = np.random.choice(n_snps_gwas, 5, replace=False)\n",
        "causal_effects = np.random.normal(0.5, 0.2, 5)  # Effect sizes\n",
        "\n",
        "# Phenotype = sum of causal effects + noise\n",
        "phenotype = np.zeros(n_gwas)\n",
        "for idx, effect in zip(causal_indices, causal_effects):\n",
        "    phenotype += effect * geno_gwas[:, idx]\n",
        "phenotype += np.random.normal(0, 1, n_gwas)  # Environmental noise\n",
        "\n",
        "print(f\"Simulated GWAS: {n_gwas} individuals, {n_snps_gwas} SNPs\")\n",
        "print(f\"Causal SNPs at indices: {sorted(causal_indices)}\")\n",
        "print(f\"Effect sizes: {causal_effects}\")\n",
        "print(f\"Phenotype variance explained by genetics: ~{np.var(phenotype - np.random.normal(0,1,n_gwas))/np.var(phenotype):.0%}\")"
      ],
      "id": "b0c1d2e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple linear regression for each SNP\n",
        "pvalues = np.zeros(n_snps_gwas)\n",
        "betas = np.zeros(n_snps_gwas)\n",
        "\n",
        "for j in range(n_snps_gwas):\n",
        "    x = geno_gwas[:, j].astype(float)\n",
        "    # Simple linear regression: y = a + b*x\n",
        "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, phenotype)\n",
        "    pvalues[j] = p_value\n",
        "    betas[j] = slope\n",
        "\n",
        "# Genome-wide significance threshold (Bonferroni)\n",
        "bonferroni = 0.05 / n_snps_gwas\n",
        "n_significant = (pvalues < bonferroni).sum()\n",
        "print(f\"Bonferroni threshold: p < {bonferroni:.2e}\")\n",
        "print(f\"Significant SNPs: {n_significant}\")\n",
        "print(f\"Causal SNPs recovered:\")\n",
        "for idx in sorted(causal_indices):\n",
        "    detected = \"DETECTED\" if pvalues[idx] < bonferroni else \"missed\"\n",
        "    print(f\"  SNP {idx}: p = {pvalues[idx]:.2e}, beta = {betas[idx]:.3f} [{detected}]\")"
      ],
      "id": "c1d2e3f4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manhattan plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "neg_log_p = -np.log10(pvalues)\n",
        "positions = np.arange(n_snps_gwas)\n",
        "\n",
        "# Color alternating \"chromosomes\" (simulated)\n",
        "chrom_size = n_snps_gwas // 5\n",
        "colors_gwas = []\n",
        "for i in range(n_snps_gwas):\n",
        "    chrom = i // chrom_size\n",
        "    colors_gwas.append('#3498db' if chrom % 2 == 0 else '#95a5a6')\n",
        "\n",
        "# Highlight significant SNPs\n",
        "for i in range(n_snps_gwas):\n",
        "    if pvalues[i] < bonferroni:\n",
        "        colors_gwas[i] = '#e74c3c'\n",
        "\n",
        "ax1.scatter(positions, neg_log_p, c=colors_gwas, s=5, alpha=0.6)\n",
        "ax1.axhline(-np.log10(bonferroni), color='red', linestyle='--', linewidth=1, label=f'Bonferroni (p={bonferroni:.1e})')\n",
        "ax1.axhline(-np.log10(5e-8), color='blue', linestyle='--', linewidth=1, alpha=0.5, label='GWAS standard (5e-8)')\n",
        "ax1.set_xlabel('SNP Position')\n",
        "ax1.set_ylabel('-log10(p-value)')\n",
        "ax1.set_title('Manhattan Plot')\n",
        "ax1.legend(fontsize=8)\n",
        "\n",
        "# Mark causal SNPs\n",
        "for idx in causal_indices:\n",
        "    if neg_log_p[idx] > 2:\n",
        "        ax1.annotate(f'SNP {idx}', (idx, neg_log_p[idx]), fontsize=7,\n",
        "                    xytext=(5, 5), textcoords='offset points')\n",
        "\n",
        "# QQ plot\n",
        "observed_sorted = np.sort(neg_log_p)\n",
        "expected_sorted = -np.log10(np.linspace(1/n_snps_gwas, 1, n_snps_gwas))\n",
        "\n",
        "ax2.scatter(expected_sorted, observed_sorted, alpha=0.3, s=10, color='steelblue')\n",
        "max_val = max(expected_sorted.max(), observed_sorted.max()) + 0.5\n",
        "ax2.plot([0, max_val], [0, max_val], 'r--', label='Null expectation')\n",
        "ax2.set_xlabel('Expected -log10(p)')\n",
        "ax2.set_ylabel('Observed -log10(p)')\n",
        "ax2.set_title('QQ Plot\\n(Inflation = population structure)')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "d2e3f4a5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 6: Effect Size Distribution"
      ],
      "id": "e3f4a5b6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "colors_vol = ['#e74c3c' if pvalues[i] < bonferroni else '#3498db' if pvalues[i] < 0.05 else '#bdc3c7' \n",
        "              for i in range(n_snps_gwas)]\n",
        "plt.scatter(betas, neg_log_p, c=colors_vol, s=10, alpha=0.5)\n",
        "plt.axhline(-np.log10(bonferroni), color='red', linestyle='--', alpha=0.7, label='Bonferroni')\n",
        "plt.axhline(-np.log10(0.05), color='blue', linestyle='--', alpha=0.3, label='Nominal p=0.05')\n",
        "plt.axvline(0, color='gray', linestyle='-', alpha=0.3)\n",
        "plt.xlabel('Effect Size (beta)')\n",
        "plt.ylabel('-log10(p-value)')\n",
        "plt.title('Volcano Plot: Effect Size vs Significance')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "print(f\"Large effect + significant (red): {sum(1 for i in range(n_snps_gwas) if pvalues[i] < bonferroni)}\")"
      ],
      "id": "f4a5b6c7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "| Concept | What you built | Why it matters |\n",
        "|---------|---------------|----------------|\n",
        "| VCF genotypes | Simulated genotype matrix | Standard variant representation |\n",
        "| Allele frequency | Site frequency spectrum | Most variants are rare |\n",
        "| HWE test | Chi-squared per SNP | Quality control + biology detection |\n",
        "| PCA | Population structure | Confounding in GWAS |\n",
        "| Fst | Population differentiation | Measures genetic distance |\n",
        "| LD | r-squared between SNPs | Tag SNPs, fine-mapping |\n",
        "| GWAS | Manhattan + QQ plots | [[Variant-Phenotype Mapping]] discovery |\n",
        "\n",
        "**Connections to the knowledge graph:**\n",
        "- [[Variant-Phenotype Mapping]] — the core GWAS objective\n",
        "- [[Variant Effect Prediction]] — predicting functional impact\n",
        "- [[Genotype-to-Phenotype Hub]] — the broader mapping problem\n",
        "- [[Fitness Landscapes]] — selection shapes allele frequencies\n",
        "- [[Context Conditionality]] — genotype effects depend on context\n",
        "- [[Conservation Laws in Living Systems]] — HWE as a conservation law\n",
        "- [[Degeneracy in Biological Systems]] — many-to-many genotype-phenotype maps\n",
        "- [[Multi-Omics Integration]] — combining genomics with other data layers\n",
        "\n",
        "**Next**: [[03_Single_Cell_Transcriptomics]] — single-cell RNA-seq with scanpy"
      ],
      "id": "a5b6c7d8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}