{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d80eef8",
   "metadata": {},
   "source": [
    "# Notebook 7: Biomedical Image Analysis\n",
    "\n",
    "**Pathology and radiology image analysis with Python**\n",
    "\n",
    "Prerequisites: Notebooks 1-6 (sequences, genomics, transcriptomics, protein structure, RNAseq, clinical)\n",
    "\n",
    "This notebook builds:\n",
    "1. Digital pathology fundamentals (IHC staining, stain deconvolution)\n",
    "2. Nuclei detection and counting\n",
    "3. Texture features (GLCM, Haralick)\n",
    "4. Radiology image concepts (MRI windowing, tissue segmentation)\n",
    "5. Image segmentation (thresholding, watershed)\n",
    "6. Feature extraction for ML classification\n",
    "7. Whole-slide image (WSI) analysis pipeline with real cancer tissue\n",
    "8. ROI (Region of Interest) analysis\n",
    "\n",
    "**Data sources**: Real immunohistochemistry (IHC) colon tissue image (`skimage.data.immunohistochemistry()`), real human mitosis image (`skimage.data.human_mitosis()`) for cell counting and watershed segmentation. Real brain MRI (`skimage.data.brain()`) for windowing and tissue segmentation. Real Aperio whole-slide image (CMU-1-Small-Region.svs, 2220x2967) for the WSI tiling pipeline.\n",
    "\n",
    "**Data setup**: Run `python data/download_all_data.py` to download the WSI file (~2 MB). The scikit-image built-in datasets require no separate download. Install: `pip install scikit-image openslide-python openslide-bin`.\n",
    "\n",
    "Estimated runtime: ~3 minutes on a laptop\n",
    "\n",
    "**Key learning outcomes:**\n",
    "1. Understand IHC staining and digital pathology workflows\n",
    "2. Segment and count cell nuclei computationally\n",
    "3. Apply MRI windowing to visualize different tissue types\n",
    "4. Extract texture and shape features for machine learning\n",
    "5. Build a complete WSI tiling pipeline from real cancer tissue\n",
    "\n",
    "---\n",
    "\n",
    "## Section 0: Setup\n",
    "\n",
    "We use **scikit-image** for image processing (including built-in real tissue and brain images), **scipy** for morphological operations, **openslide** for reading whole-slide images, and **matplotlib** for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage import data, filters, segmentation, measure, morphology, feature, color\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import openslide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0746b141",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Digital Pathology Fundamentals\n",
    "\n",
    "Digital pathology converts glass slides into high-resolution digital images.\n",
    "Common staining protocols include:\n",
    "\n",
    "- **H&E** (Hematoxylin & Eosin): the gold standard for general histology\n",
    "- **IHC** (Immunohistochemistry): hematoxylin counterstain + DAB for specific proteins\n",
    "\n",
    "In both protocols, **hematoxylin** (blue/purple) stains nuclei and **eosin/DAB** stains\n",
    "cytoplasm or specific protein targets. We use a **real IHC colon tissue image** from\n",
    "scikit-image and apply **HED color deconvolution** to separate stain components.\n",
    "\n",
    "Reference [[Hierarchical Composition]] -- tissue has a multi-scale hierarchy:\n",
    "molecules -> organelles -> cells -> tissues -> organs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real IHC-stained colon tissue image\n",
    "ihc_rgb = data.immunohistochemistry()  # Real IHC image (512x512x3, uint8)\n",
    "image = ihc_rgb / 255.0\n",
    "\n",
    "# HED stain deconvolution\n",
    "ihc_hed = color.rgb2hed(image)\n",
    "hematoxylin = ihc_hed[:, :, 0]  # Nuclei (blue/purple)\n",
    "eosin = ihc_hed[:, :, 1]        # Cytoplasm/stroma (pink)\n",
    "dab = ihc_hed[:, :, 2]          # DAB protein marker (brown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d432482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the hematoxylin channel to find nuclei (Otsu's method)\n",
    "threshold = filters.threshold_otsu(hematoxylin)\n",
    "nuclei_mask = hematoxylin > threshold\n",
    "nuclei_mask = morphology.remove_small_objects(nuclei_mask, min_size=30)\n",
    "nuclei_mask = ndimage.binary_fill_holes(nuclei_mask)\n",
    "labeled = measure.label(nuclei_mask)\n",
    "regions = measure.regionprops(labeled, intensity_image=hematoxylin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9046e39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Nuclear Morphometry\n",
    "\n",
    "Nuclear morphometry measures the size, shape, and texture of cell nuclei.\n",
    "Abnormal nuclear features are hallmarks of cancer:\n",
    "\n",
    "- Enlarged nuclei (increased DNA content)\n",
    "- Irregular shape (pleomorphism)\n",
    "- Increased N:C ratio (nucleus:cytoplasm)\n",
    "\n",
    "Key features used in pathology grading:\n",
    "\n",
    "$$\\text{Circularity} = \\frac{4\\pi \\cdot \\text{Area}}{\\text{Perimeter}^2}$$\n",
    "\n",
    "A perfect circle has circularity = 1.0. Cancer nuclei typically have lower values.\n",
    "\n",
    "Reference [[Quality Control in Living Systems]] -- normal cells maintain strict size\n",
    "and shape constraints; cancer cells lose this quality control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a68d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "for region in regions:\n",
    "    features_list.append({\n",
    "        'area': region.area,\n",
    "        'perimeter': region.perimeter,\n",
    "        'eccentricity': region.eccentricity,\n",
    "        'solidity': region.solidity,\n",
    "        'mean_intensity': region.mean_intensity,\n",
    "        'circularity': 4 * np.pi * region.area / (region.perimeter ** 2 + 1e-10),\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc5d31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Radiology Image Analysis\n",
    "\n",
    "Radiology images (CT, MRI, X-ray) use different physics than pathology:\n",
    "\n",
    "- **CT**: X-ray attenuation in Hounsfield Units (HU). Air = -1000, Water = 0, Bone = +1000\n",
    "- **MRI**: Magnetic resonance signal intensity (arbitrary units, tissue-dependent contrast)\n",
    "- **X-ray**: Projection imaging (2D shadow of 3D anatomy)\n",
    "\n",
    "\"Windowing\" adjusts contrast to visualize specific tissues. We demonstrate with\n",
    "**real brain MRI data** from `skimage.data.brain()` (T1-weighted, 10 axial slices).\n",
    "\n",
    "Reference [[Signal Processing in Biological Systems]] -- windowing is a form of\n",
    "signal filtering that extracts task-relevant information from a shared data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a8cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_window(img, center, width):\n",
    "    \"\"\"Apply intensity window (center/width) to radiological image.\"\"\"\n",
    "    low = center - width / 2\n",
    "    high = center + width / 2\n",
    "    windowed = np.clip(img, low, high)\n",
    "    windowed = (windowed - low) / (high - low)\n",
    "    return windowed\n",
    "\n",
    "brain_volume = data.brain()  # T1-weighted MRI, (10, 256, 256), uint16\n",
    "mri_slice = brain_volume[5].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5452119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Otsu tissue classification\n",
    "thresholds = filters.threshold_multiotsu(brain_pixels, classes=3)\n",
    "# Segments into: Background, CSF/dark, Gray matter, White matter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7bf9fb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Image Segmentation Pipeline\n",
    "\n",
    "Segmentation separates structures of interest from background. Methods:\n",
    "\n",
    "- **Thresholding**: simple intensity cutoff (Otsu's method)\n",
    "- **Watershed**: separates touching objects using topology\n",
    "- **Deep learning**: U-Net, nnU-Net (not covered here, requires GPU)\n",
    "\n",
    "The watershed algorithm treats the image as a topographic surface using\n",
    "**real human mitosis fluorescence microscopy** from `skimage.data.human_mitosis()`.\n",
    "\n",
    "Reference [[Figure-Ground Decomposition]] -- segmentation is the computational\n",
    "analog of perceptual figure-ground separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mitosis_image = data.human_mitosis()  # Grayscale, uint8, 512x512\n",
    "\n",
    "# Distance transform for watershed\n",
    "binary = mitosis_float > filters.threshold_otsu(mitosis_float)\n",
    "distance = ndimage.distance_transform_edt(binary)\n",
    "local_max = feature.peak_local_max(distance, min_distance=7, labels=binary)\n",
    "labels_ws = segmentation.watershed(-distance, markers, mask=binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cba6015",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5: Feature Extraction for ML\n",
    "\n",
    "Machine learning on medical images requires features. Two approaches:\n",
    "\n",
    "1. **Handcrafted**: texture (GLCM), shape (morphometry), intensity statistics -- interpretable\n",
    "2. **Learned**: CNN features from pretrained networks -- more powerful but less interpretable\n",
    "\n",
    "The Gray-Level Co-occurrence Matrix (GLCM) captures texture by counting how often\n",
    "pairs of pixel intensities occur at specific spatial relationships. Haralick features:\n",
    "\n",
    "- **Contrast**: intensity difference between neighboring pixels\n",
    "- **Homogeneity**: closeness of pixel pair distribution to the GLCM diagonal\n",
    "- **Energy**: sum of squared GLCM elements (uniformity)\n",
    "- **Correlation**: linear dependency between neighboring pixels\n",
    "\n",
    "Reference [[Information Compression in Biology]] -- feature extraction compresses\n",
    "images into biologically meaningful representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_texture_features(patch):\n",
    "    \"\"\"Compute GLCM-based texture features from a grayscale patch.\"\"\"\n",
    "    patch_uint8 = (patch * 255).astype(np.uint8)\n",
    "    glcm = graycomatrix(patch_uint8, distances=[1, 3],\n",
    "                        angles=[0, np.pi / 4, np.pi / 2],\n",
    "                        levels=256, symmetric=True, normed=True)\n",
    "    features = {}\n",
    "    for prop in ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']:\n",
    "        values = graycoprops(glcm, prop)\n",
    "        features[prop] = values.mean()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77562c84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Whole-Slide Image (WSI) Analysis\n",
    "\n",
    "Whole-slide images (WSI) are too large to process at once -- a typical 40x scan is\n",
    "50,000 x 100,000+ pixels (several gigabytes uncompressed). The standard approach:\n",
    "\n",
    "1. **Tissue detection**: find tissue regions at low magnification\n",
    "2. **Tiling**: extract overlapping patches at high magnification\n",
    "3. **Per-tile analysis**: run feature extraction or deep learning on each tile\n",
    "4. **Aggregation**: combine tile-level results into slide-level predictions\n",
    "\n",
    "We use a **real Aperio whole-slide image** (CMU-1-Small-Region.svs) read via\n",
    "**OpenSlide**, the standard library for reading vendor-specific WSI formats.\n",
    "\n",
    "This is a natural application of [[Hierarchical Composition]] -- information flows\n",
    "from pixels to patches to slide-level diagnosis.\n",
    "\n",
    "Reference [[Tissue Topology]] -- the spatial arrangement of cell types within\n",
    "tissue carries diagnostic information beyond individual cell features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f133e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load real WSI via OpenSlide\n",
    "slide = openslide.OpenSlide(\"data/nb07/CMU-1-Small-Region.svs\")\n",
    "wsi_region = slide.read_region((0, 0), 0, slide.dimensions)\n",
    "wsi_image = np.array(wsi_region.convert(\"RGB\")) / 255.0\n",
    "\n",
    "# Tile and compute nuclear density per tile\n",
    "tile_size = 256\n",
    "for y_tile in range(0, h - tile_size + 1, tile_size):\n",
    "    for x_tile in range(0, w - tile_size + 1, tile_size):\n",
    "        tile_rgb = wsi_image[y_tile:y_tile + tile_size, x_tile:x_tile + tile_size]\n",
    "        # Skip background, detect nuclei via HED + Otsu per tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c40289e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: ROI Analysis and Feature Aggregation\n",
    "\n",
    "Region of Interest (ROI) analysis combines spatial information with feature\n",
    "extraction. Aggregation strategies for slide-level prediction:\n",
    "\n",
    "- **Mean pooling**: average features across all tiles\n",
    "- **Max pooling**: take the \"worst\" (most abnormal) tile\n",
    "- **Multiple Instance Learning (MIL)**: learn which tiles matter\n",
    "\n",
    "This connects to [[Selective Catabolism]] -- the system selectively processes\n",
    "the most informative regions rather than treating all tissue equally.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Concept | What you built | Why it matters |\n",
    "|---------|---------------|----------------|\n",
    "| Real IHC tissue | skimage.data.immunohistochemistry() | [[Hierarchical Composition]] in tissue |\n",
    "| Stain deconvolution | HED color space separation | Isolate nuclear vs cytoplasmic signal |\n",
    "| Nuclear segmentation | Otsu + morphology on real tissue | Count and characterize cells |\n",
    "| Morphometry | Area, shape, intensity features | Cancer grading criteria |\n",
    "| MRI windowing | Real brain MRI (skimage.data.brain) | Same data, different views |\n",
    "| Tissue classification | Multi-Otsu brain segmentation | Automated anatomy parsing |\n",
    "| Watershed | Real cell separation (human mitosis) | [[Figure-Ground Decomposition]] |\n",
    "| GLCM texture | Statistical texture features | ML input for classification |\n",
    "| WSI pipeline | Real Aperio cancer tissue (OpenSlide) | Scalable digital pathology |\n",
    "| ROI analysis | Feature aggregation | [[Selective Catabolism]] in diagnostics |\n",
    "\n",
    "**The complete series:**\n",
    "- [[01_Sequence_Analysis_Fundamentals]] -- Biopython, the Central Dogma\n",
    "- [[02_Genomic_Variant_Analysis]] -- Population genetics, GWAS\n",
    "- [[03_Single_Cell_Transcriptomics]] -- scanpy, cell type discovery\n",
    "- [[04_Protein_Structure_Drug_Discovery]] -- Structure and drug design\n",
    "- [[05_Bulk_RNAseq_Differential_Expression]] -- Differential expression analysis\n",
    "- [[06_Clinical_Biomedical_Informatics]] -- Clinical data and survival analysis\n",
    "- [[07_Biomedical_Image_Analysis]] -- Pathology and radiology (this notebook)\n",
    "\n",
    "**Next**: [[08_Plant_Biology_Agricultural_Genomics]] -- crop science and agricultural applications"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
